common:
  disable_tqdm: true # set true when using nohup

path:
  checkpoint: "sylber"
  quantizer1: "models/sylber/quantizer1.npy"
  quantizer2: "models/sylber/quantizer2.npy"
  segment_dir: "segments/sylber"
  result: "results/sylber.json"

dataset:
  root: "data" # ${root}/LibriSpeech/train-clean-100, train-clean-360, ...
  train_file: "src/sdhubert/files/librispeech_train_10Ksubset.txt"
  dev_file: "src/sdhubert/files/librispeech_val.txt"
  test_file: "src/sdhubert/files/librispeech_test.txt"
  dev_alignment: "src/sdhubert/files/librispeech_syllable_val.json"
  test_alignment: "src/sdhubert/files/librispeech_syllable_test.json"

dataloader:
  num_workers: 30

model:
  model_type: "sylber"

quantizer:
  n_clusters1: 16384
  n_clusters2: 4096
  niter: 100
  nredo: 5
  verbose: true
  random_state: ${common.seed}
  gpu: true
  min_points_per_centroid: 1
  max_points_per_centroid: null
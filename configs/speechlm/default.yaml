dataset:
  ll_dir: "data/librilight"
  lh_dir: "data/libriheavy"
  ext_audio: ".flac"
  manifest_prefix: "data/manifest"

  name: "ryota-komatsu/s5-hubert"

  HF_HOME: "~/.cache/huggingface"
  APP_DIR: "data/zr-data"
  tSC_DIR: "data/tSC"

model_args:
  vocab_size: 16386
  hidden_size: 768
  intermediate_size: 2048
  num_hidden_layers: 12
  num_attention_heads: 12
  num_key_value_heads: 12
  head_dim: 64
  max_position_embeddings: 256
  tie_word_embeddings: true
  rope_theta: 1000.0
  pad_token_id: 16385
  bos_token_id: 16384
  eos_token_id: 16385

training_args:
  output_dir: "models/speechlm"
  per_device_train_batch_size: 32
  per_device_eval_batch_size: 32
  gradient_accumulation_steps: 16
  learning_rate: 0.0005
  weight_decay: 0.01
  adam_beta1: 0.9
  adam_beta2: 0.98
  max_grad_norm: 0.5
  max_steps: 100000
  lr_scheduler_type: "cosine_with_min_lr"
  lr_scheduler_kwargs: {"min_lr": 0.00005}
  warmup_steps: 100
  save_steps: 1000
  save_total_limit: null
  bf16: true
  eval_steps: 5000
  remove_unused_columns: false
  ddp_find_unused_parameters: false
  resume_from_checkpoint: null

speech2unit:
  model_name_or_path: "ryota-komatsu/s5-hubert"
  vocab_size: 16384